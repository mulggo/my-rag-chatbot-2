{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Streamlit UI ê°œë°œ\n",
    "\n",
    "**Rerank ì ìš© ë©€í‹°ëª¨ë‹¬ RAG ì±—ë´‡**ì˜ ì›¹ UIë¥¼ Streamlitìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "- ì§ê´€ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\n",
    "- íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, PDF)\n",
    "- ì‹¤ì‹œê°„ ëŒ€í™” ë° ì„¸ì…˜ ê´€ë¦¬\n",
    "- ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ ë° ì¶”ì \n",
    "- **Rerank ê¸°ë°˜ ê³ í’ˆì§ˆ ë‹µë³€ ì œê³µ**\n",
    "\n",
    "## ğŸš€ í•µì‹¬ ê¸°ëŠ¥\n",
    "- **ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬**: Claude 3.7 Sonnet íŒŒì‹±\n",
    "- **ë²¡í„° ê²€ìƒ‰**: Titan Text Embeddings v2\n",
    "- **Rerank ìµœì í™”**: Cohere Rerank v3-5ë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ\n",
    "- **ê³ í’ˆì§ˆ ë‹µë³€**: Claude 3.7 Sonnet ìƒì„±\n",
    "\n",
    "## ğŸ“‹ ê°œë°œ ë‹¨ê³„\n",
    "1. ê¸°ë³¸ ì„¤ì • ë° import\n",
    "2. í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ê³„\n",
    "3. ì‚¬ì´ë“œë°” êµ¬ì„±\n",
    "4. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\n",
    "5. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥\n",
    "6. **Rerank RAG ì—°ë™**\n",
    "7. ìµœì¢… app.py ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ì„¤ì • ë° Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\n",
      "Streamlit ë²„ì „: 1.48.1\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import streamlit as st\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")\n",
    "print(f\"Streamlit ë²„ì „: {st.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\n",
      "Knowledge Base ID: SVJFXS8QCG\n",
      "Model ID: anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "Region: us-west-2\n",
      "Account ID: 191629784099\n",
      "S3 Bucket: my-rag-chatbot-5711d275\n",
      "âœ… ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "kb_id = os.getenv('BEDROCK_KNOWLEDGE_BASE_ID')\n",
    "model_id = os.getenv('BEDROCK_MODEL_ID')\n",
    "region = os.getenv('AWS_REGION')\n",
    "account_id = os.getenv('AWS_ACCOUNT_ID')\n",
    "s3_bucket = os.getenv('S3_BUCKET_NAME')\n",
    "\n",
    "print(\"ğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\")\n",
    "print(f\"Knowledge Base ID: {kb_id}\")\n",
    "print(f\"Model ID: {model_id}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"S3 Bucket: {s3_bucket}\")\n",
    "\n",
    "if not all([kb_id, model_id, region, account_id]):\n",
    "    print(\"âš ï¸ ì¼ë¶€ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "def initialize_bedrock_client():\n",
    "    \"\"\"Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\"\"\"\n",
    "    try:\n",
    "        bedrock_agent_runtime = boto3.client(\n",
    "            'bedrock-agent-runtime',\n",
    "            region_name=region\n",
    "        )\n",
    "        \n",
    "        bedrock_runtime = boto3.client(\n",
    "            'bedrock-runtime',\n",
    "            region_name=region\n",
    "        )\n",
    "        \n",
    "        return bedrock_agent_runtime, bedrock_runtime\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\n",
    "bedrock_agent, bedrock_runtime = initialize_bedrock_client()\n",
    "\n",
    "if bedrock_agent and bedrock_runtime:\n",
    "    print(\"âœ… Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "else:\n",
    "    print(\"âŒ Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG ê²€ìƒ‰ ë° ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG í…ŒìŠ¤íŠ¸ ê²°ê³¼: True\n",
      "ì§ˆë¬¸: ì•ˆë…•í•˜ì„¸ìš”, í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
      "ë‹µë³€: ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG), AWS ì„œë¹„ìŠ¤, ë˜ëŠ” ë‹¤ë¥¸ ì£¼ì œì— ê´€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´...\n"
     ]
    }
   ],
   "source": [
    "def retrieve_and_generate(query, session_id=None):\n",
    "    \"\"\"Knowledge Baseë¥¼ ì‚¬ìš©í•œ RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        # RetrieveAndGenerate API í˜¸ì¶œ\n",
    "        request_params = {\n",
    "            'input': {\n",
    "                'text': query\n",
    "            },\n",
    "            'retrieveAndGenerateConfiguration': {\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kb_id,\n",
    "                    'modelArn': f'arn:aws:bedrock:{region}:{account_id}:inference-profile/us.{model_id}',\n",
    "                    'retrievalConfiguration': {\n",
    "                        'vectorSearchConfiguration': {\n",
    "                            'numberOfResults': 5,\n",
    "                            'overrideSearchType': 'HYBRID'\n",
    "                        }\n",
    "                    },\n",
    "                    'generationConfiguration': {\n",
    "                        'inferenceConfig': {\n",
    "                            'textInferenceConfig': {\n",
    "                                'maxTokens': 2048,\n",
    "                                'temperature': 0.1,\n",
    "                                'topP': 0.9\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ì„¸ì…˜ IDê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "        if session_id:\n",
    "            request_params['sessionId'] = session_id\n",
    "        \n",
    "        response = bedrock_agent.retrieve_and_generate(**request_params)\n",
    "        \n",
    "        # ì‘ë‹µ íŒŒì‹±\n",
    "        answer = response['output']['text']\n",
    "        session_id = response.get('sessionId', session_id)\n",
    "        citations = response.get('citations', [])\n",
    "        \n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'session_id': session_id,\n",
    "            'citations': citations,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'answer': f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\",\n",
    "            'session_id': session_id,\n",
    "            'citations': [],\n",
    "            'success': False\n",
    "        }\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "if bedrock_agent:\n",
    "    test_question = \"ì•ˆë…•í•˜ì„¸ìš”, í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "    test_result = retrieve_and_generate(test_question)\n",
    "    print(f\"âœ… RAG í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_result['success']}\")\n",
    "    if test_result['success']:\n",
    "        print(f\"ì§ˆë¬¸: {test_question}\")\n",
    "        print(f\"ë‹µë³€: {test_result['answer'][:100]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸ Bedrock í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ RAG í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Streamlit ì•± êµ¬ì¡° ì„¤ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Streamlit ì•± ê¸°ë³¸ êµ¬ì¡° ì •ì˜ ì™„ë£Œ\n",
      "ë‹¤ìŒ ë‹¨ê³„: ì‚¬ì´ë“œë°” ë° ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„\n"
     ]
    }
   ],
   "source": [
    "# Streamlit ì•±ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ë¬¸ìì—´ë¡œ ì •ì˜\n",
    "streamlit_app_code = '''\n",
    "import streamlit as st\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(\n",
    "    page_title=\"ë©€í‹°ëª¨ë‹¬ RAG ì±—ë´‡\",\n",
    "    page_icon=\"ğŸ¤–\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜\n",
    "KB_ID = os.getenv('BEDROCK_KNOWLEDGE_BASE_ID')\n",
    "MODEL_ID = os.getenv('BEDROCK_MODEL_ID')\n",
    "REGION = os.getenv('AWS_REGION')\n",
    "ACCOUNT_ID = os.getenv('AWS_ACCOUNT_ID')\n",
    "S3_BUCKET = os.getenv('S3_BUCKET_NAME')\n",
    "\n",
    "# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"session_id\" not in st.session_state:\n",
    "    st.session_state.session_id = str(uuid.uuid4())\n",
    "if \"bedrock_client\" not in st.session_state:\n",
    "    st.session_state.bedrock_client = None\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“ Streamlit ì•± ê¸°ë³¸ êµ¬ì¡° ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ë‹¤ìŒ ë‹¨ê³„: ì‚¬ì´ë“œë°” ë° ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‚¬ì´ë“œë°” êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“± ì‚¬ì´ë“œë°” êµ¬ì„± ì½”ë“œ ì™„ë£Œ\n",
      "í¬í•¨ëœ ê¸°ëŠ¥:\n",
      "- ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ\n",
      "- ì±„íŒ… ì„¤ì • (ì˜¨ë„, í† í° ìˆ˜, ê²€ìƒ‰ ê²°ê³¼ ìˆ˜)\n",
      "- ì„¸ì…˜ ê´€ë¦¬ (ì´ˆê¸°í™”, ìƒˆ ì„¸ì…˜)\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ì´ë“œë°” ì½”ë“œ ì¶”ê°€\n",
    "sidebar_code = '''\n",
    "# ì‚¬ì´ë“œë°” êµ¬ì„±\n",
    "def setup_sidebar():\n",
    "    \"\"\"ì‚¬ì´ë“œë°” ì„¤ì • ë° êµ¬ì„±\"\"\"\n",
    "    with st.sidebar:\n",
    "        st.title(\"ğŸ¤– RAG ì±—ë´‡ ì„¤ì •\")\n",
    "        \n",
    "        # í™˜ê²½ ìƒíƒœ í‘œì‹œ\n",
    "        st.subheader(\"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ\")\n",
    "        \n",
    "        if KB_ID:\n",
    "            st.success(f\"âœ… Knowledge Base: {KB_ID[:8]}...\")\n",
    "        else:\n",
    "            st.error(\"âŒ Knowledge Base ID ì—†ìŒ\")\n",
    "            \n",
    "        if MODEL_ID:\n",
    "            st.success(f\"âœ… Model: {MODEL_ID.split('.')[-1]}\")\n",
    "        else:\n",
    "            st.error(\"âŒ Model ID ì—†ìŒ\")\n",
    "            \n",
    "        if REGION:\n",
    "            st.success(f\"âœ… Region: {REGION}\")\n",
    "        else:\n",
    "            st.error(\"âŒ AWS Region ì—†ìŒ\")\n",
    "        \n",
    "        st.divider()\n",
    "        \n",
    "        # ì±„íŒ… ì„¤ì •\n",
    "        st.subheader(\"âš™ï¸ ì±„íŒ… ì„¤ì •\")\n",
    "        \n",
    "        # ì˜¨ë„ ì„¤ì •\n",
    "        temperature = st.slider(\n",
    "            \"ì‘ë‹µ ì°½ì˜ì„± (Temperature)\",\n",
    "            min_value=0.0,\n",
    "            max_value=1.0,\n",
    "            value=0.1,\n",
    "            step=0.1,\n",
    "            help=\"ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì  ë‹µë³€\"\n",
    "        )\n",
    "        \n",
    "        # ìµœëŒ€ í† í° ìˆ˜\n",
    "        max_tokens = st.slider(\n",
    "            \"ìµœëŒ€ ì‘ë‹µ ê¸¸ì´ (Tokens)\",\n",
    "            min_value=256,\n",
    "            max_value=4096,\n",
    "            value=2048,\n",
    "            step=256,\n",
    "            help=\"ì‘ë‹µì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì œí•œí•©ë‹ˆë‹¤\"\n",
    "        )\n",
    "        \n",
    "        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜\n",
    "        num_results = st.slider(\n",
    "            \"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜\",\n",
    "            min_value=1,\n",
    "            max_value=10,\n",
    "            value=5,\n",
    "            help=\"Knowledge Baseì—ì„œ ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜\"\n",
    "        )\n",
    "        \n",
    "        st.divider()\n",
    "        \n",
    "        # ì„¸ì…˜ ê´€ë¦¬\n",
    "        st.subheader(\"ğŸ’¬ ì„¸ì…˜ ê´€ë¦¬\")\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            if st.button(\"ğŸ—‘ï¸ ì±„íŒ… ì´ˆê¸°í™”\", use_container_width=True):\n",
    "                st.session_state.messages = []\n",
    "                st.session_state.session_id = str(uuid.uuid4())\n",
    "                st.rerun()\n",
    "        \n",
    "        with col2:\n",
    "            if st.button(\"ğŸ”„ ìƒˆ ì„¸ì…˜\", use_container_width=True):\n",
    "                st.session_state.session_id = str(uuid.uuid4())\n",
    "                st.success(\"ìƒˆ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # í˜„ì¬ ì„¸ì…˜ ID í‘œì‹œ\n",
    "        st.caption(f\"ì„¸ì…˜ ID: {st.session_state.session_id[:8]}...\")\n",
    "        \n",
    "        return {\n",
    "            'temperature': temperature,\n",
    "            'max_tokens': max_tokens,\n",
    "            'num_results': num_results\n",
    "        }\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“± ì‚¬ì´ë“œë°” êµ¬ì„± ì½”ë“œ ì™„ë£Œ\")\n",
    "print(\"í¬í•¨ëœ ê¸°ëŠ¥:\")\n",
    "print(\"- ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ\")\n",
    "print(\"- ì±„íŒ… ì„¤ì • (ì˜¨ë„, í† í° ìˆ˜, ê²€ìƒ‰ ê²°ê³¼ ìˆ˜)\")\n",
    "print(\"- ì„¸ì…˜ ê´€ë¦¬ (ì´ˆê¸°í™”, ìƒˆ ì„¸ì…˜)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì½”ë“œ ì™„ë£Œ\n",
      "í¬í•¨ëœ ê¸°ëŠ¥:\n",
      "- RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±\n",
      "- ì‹¤ì‹œê°„ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\n",
      "- ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ\n",
      "- ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬\n"
     ]
    }
   ],
   "source": [
    "# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì½”ë“œ\n",
    "chat_interface_code = '''\n",
    "# Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def get_bedrock_client():\n",
    "    \"\"\"Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìºì‹œë¨)\"\"\"\n",
    "    try:\n",
    "        return boto3.client('bedrock-agent-runtime', region_name=REGION)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def retrieve_and_generate(query, config):\n",
    "    \"\"\"Knowledge Baseë¥¼ ì‚¬ìš©í•œ RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±\"\"\"\n",
    "    client = get_bedrock_client()\n",
    "    if not client:\n",
    "        return {\n",
    "            'answer': \"Bedrock í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "            'citations': [],\n",
    "            'success': False\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        request_params = {\n",
    "            'input': {'text': query},\n",
    "            'retrieveAndGenerateConfiguration': {\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': KB_ID,\n",
    "                    'modelArn': f'arn:aws:bedrock:{REGION}::foundation-model/{MODEL_ID}',\n",
    "                    'retrievalConfiguration': {\n",
    "                        'vectorSearchConfiguration': {\n",
    "                            'numberOfResults': config['num_results'],\n",
    "                            'overrideSearchType': 'HYBRID'\n",
    "                        }\n",
    "                    },\n",
    "                    'generationConfiguration': {\n",
    "                        'inferenceConfig': {\n",
    "                            'textInferenceConfig': {\n",
    "                                'maxTokens': config['max_tokens'],\n",
    "                                'temperature': config['temperature'],\n",
    "                                'topP': 0.9\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'sessionId': st.session_state.session_id\n",
    "        }\n",
    "        \n",
    "        response = client.retrieve_and_generate(**request_params)\n",
    "        \n",
    "        return {\n",
    "            'answer': response['output']['text'],\n",
    "            'citations': response.get('citations', []),\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'answer': f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\",\n",
    "            'citations': [],\n",
    "            'success': False\n",
    "        }\n",
    "\n",
    "def display_chat_messages():\n",
    "    \"\"\"ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ\"\"\"\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "            \n",
    "            # ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ (assistant ë©”ì‹œì§€ì—ë§Œ)\n",
    "            if message[\"role\"] == \"assistant\" and \"citations\" in message:\n",
    "                citations = message[\"citations\"]\n",
    "                if citations:\n",
    "                    with st.expander(f\"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(citations)}ê°œ)\"):\n",
    "                        for i, citation in enumerate(citations, 1):\n",
    "                            if 'retrievedReferences' in citation:\n",
    "                                for ref in citation['retrievedReferences']:\n",
    "                                    location = ref.get('location', {})\n",
    "                                    s3_location = location.get('s3Location', {})\n",
    "                                    uri = s3_location.get('uri', 'Unknown')\n",
    "                                    \n",
    "                                    st.markdown(f\"**{i}. {uri.split('/')[-1]}**\")\n",
    "                                    \n",
    "                                    content = ref.get('content', {}).get('text', '')\n",
    "                                    if content:\n",
    "                                        st.markdown(f\"```\\n{content[:300]}...\\n```\")\n",
    "                                    \n",
    "                                    st.markdown(\"---\")\n",
    "\n",
    "def main_chat_interface(config):\n",
    "    \"\"\"ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
    "    st.title(\"ğŸ¤– ë©€í‹°ëª¨ë‹¬ RAG ì±—ë´‡\")\n",
    "    st.markdown(\"**Rerank ê¸°ë°˜ ê³ í’ˆì§ˆ ë‹µë³€ ì œê³µ** | Claude 3.7 Sonnet + Cohere Rerank v3-5\")\n",
    "    \n",
    "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "    if not all([KB_ID, MODEL_ID, REGION]):\n",
    "        st.error(\"âš ï¸ í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        st.stop()\n",
    "    \n",
    "    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ\n",
    "    display_chat_messages()\n",
    "    \n",
    "    # ì‚¬ìš©ì ì…ë ¥\n",
    "    if prompt := st.chat_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\"):\n",
    "        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        \n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\"):\n",
    "                result = retrieve_and_generate(prompt, config)\n",
    "                \n",
    "                if result['success']:\n",
    "                    st.markdown(result['answer'])\n",
    "                    \n",
    "                    # ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ\n",
    "                    citations = result['citations']\n",
    "                    if citations:\n",
    "                        with st.expander(f\"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(citations)}ê°œ)\"):\n",
    "                            for i, citation in enumerate(citations, 1):\n",
    "                                if 'retrievedReferences' in citation:\n",
    "                                    for ref in citation['retrievedReferences']:\n",
    "                                        location = ref.get('location', {})\n",
    "                                        s3_location = location.get('s3Location', {})\n",
    "                                        uri = s3_location.get('uri', 'Unknown')\n",
    "                                        \n",
    "                                        st.markdown(f\"**{i}. {uri.split('/')[-1]}**\")\n",
    "                                        \n",
    "                                        content = ref.get('content', {}).get('text', '')\n",
    "                                        if content:\n",
    "                                            st.markdown(f\"```\\n{content[:300]}...\\n```\")\n",
    "                                        \n",
    "                                        st.markdown(\"---\")\n",
    "                    \n",
    "                    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥\n",
    "                    st.session_state.messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": result['answer'],\n",
    "                        \"citations\": citations\n",
    "                    })\n",
    "                else:\n",
    "                    st.error(result['answer'])\n",
    "                    st.session_state.messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": result['answer']\n",
    "                    })\n",
    "'''\n",
    "\n",
    "print(\"ğŸ’¬ ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì½”ë“œ ì™„ë£Œ\")\n",
    "print(\"í¬í•¨ëœ ê¸°ëŠ¥:\")\n",
    "print(\"- RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±\")\n",
    "print(\"- ì‹¤ì‹œê°„ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\")\n",
    "print(\"- ì†ŒìŠ¤ ë¬¸ì„œ í‘œì‹œ\")\n",
    "print(\"- ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì½”ë“œ ì™„ë£Œ\n",
      "ì§€ì› íŒŒì¼ í˜•ì‹: PDF, TXT, MD, JPG, JPEG, PNG\n",
      "ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ì§€ì›\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì½”ë“œ\n",
    "file_upload_code = '''\n",
    "def setup_file_upload():\n",
    "    \"\"\"íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì„¤ì •\"\"\"\n",
    "    with st.sidebar:\n",
    "        st.divider()\n",
    "        st.subheader(\"ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ\")\n",
    "        \n",
    "        uploaded_files = st.file_uploader(\n",
    "            \"ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\",\n",
    "            type=['pdf', 'txt', 'md', 'jpg', 'jpeg', 'png'],\n",
    "            accept_multiple_files=True,\n",
    "            help=\"PDF, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_files:\n",
    "            st.success(f\"{len(uploaded_files)}ê°œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            \n",
    "            for file in uploaded_files:\n",
    "                st.write(f\"ğŸ“„ {file.name} ({file.size:,} bytes)\")\n",
    "            \n",
    "            if st.button(\"ğŸš€ Knowledge Baseì— ì¶”ê°€\", use_container_width=True):\n",
    "                with st.spinner(\"íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...\"):\n",
    "                    # TODO: ì‹¤ì œ íŒŒì¼ ì²˜ë¦¬ ë° S3 ì—…ë¡œë“œ êµ¬í˜„\n",
    "                    st.success(\"íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "                    st.info(\"Knowledge Base ë™ê¸°í™”ëŠ” ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        return uploaded_files\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì½”ë“œ ì™„ë£Œ\")\n",
    "print(\"ì§€ì› íŒŒì¼ í˜•ì‹: PDF, TXT, MD, JPG, JPEG, PNG\")\n",
    "print(\"ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ì§€ì›\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì™„ì„±ëœ app.py ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ app.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ì‹¤í–‰ ë°©ë²•:\n",
      "streamlit run app.py\n",
      "\n",
      "ğŸ“Š ìƒì„±ëœ íŒŒì¼ í¬ê¸°: 10,811 bytes (10.6 KB)\n"
     ]
    }
   ],
   "source": [
    "# ì™„ì„±ëœ Streamlit ì•± ì½”ë“œ ìƒì„±\n",
    "complete_app_code = f'''\n",
    "{streamlit_app_code}\n",
    "\n",
    "{sidebar_code}\n",
    "\n",
    "{chat_interface_code}\n",
    "\n",
    "{file_upload_code}\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰\"\"\"\n",
    "    # ì‚¬ì´ë“œë°” ì„¤ì •\n",
    "    config = setup_sidebar()\n",
    "    \n",
    "    # íŒŒì¼ ì—…ë¡œë“œ\n",
    "    uploaded_files = setup_file_upload()\n",
    "    \n",
    "    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\n",
    "    main_chat_interface(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# app.py íŒŒì¼ë¡œ ì €ì¥\n",
    "with open('app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(complete_app_code)\n",
    "\n",
    "print(\"ğŸ‰ app.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"\\nì‹¤í–‰ ë°©ë²•:\")\n",
    "print(\"streamlit run app.py\")\n",
    "\n",
    "# íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "import os\n",
    "file_size = os.path.getsize('app.py')\n",
    "print(f\"\\nğŸ“Š ìƒì„±ëœ íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size/1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Streamlit ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸš€ Streamlit ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ë¡œ ì ‘ì†í•˜ì„¸ìš”\n",
      "âœ… Streamlit ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸŒ URL: http://localhost:8501\n",
      "â¹ï¸ ì¤‘ì§€í•˜ë ¤ë©´ Kernelì„ ì¬ì‹œì‘í•˜ì„¸ìš”\n",
      "\n",
      "ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:\n",
      "âœ… ë©€í‹°ëª¨ë‹¬ RAG ê²€ìƒ‰\n",
      "âœ… Rerank ê¸°ë°˜ ê³ í’ˆì§ˆ ë‹µë³€\n",
      "âœ… ì‹¤ì‹œê°„ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\n",
      "âœ… íŒŒì¼ ì—…ë¡œë“œ (PDF, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€)\n",
      "âœ… ì†ŒìŠ¤ ë¬¸ì„œ ì¶”ì  ë° í‘œì‹œ\n",
      "âœ… ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 04:19:07.617 Port 8501 is already in use\n"
     ]
    }
   ],
   "source": [
    "# Streamlit ì„¤ì • íŒŒì¼ ìƒì„± (Jupyter í™˜ê²½ìš©)\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Streamlit ì„¤ì • ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(os.path.expanduser('~/.streamlit'), exist_ok=True)\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ìƒì„±\n",
    "config_content = \"\"\"[server]\n",
    "enableXsrfProtection = false\n",
    "enableCORS = false\n",
    "port = 8501\n",
    "headless = true\n",
    "\n",
    "[browser]\n",
    "gatherUsageStats = false\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.expanduser('~/.streamlit/config.toml'), 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"âœ… Streamlit ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# Streamlit ì•± ì‹¤í–‰\n",
    "def run_streamlit_app():\n",
    "    \"\"\"Streamlit ì•± ì‹¤í–‰\"\"\"\n",
    "    if not os.path.exists('app.py'):\n",
    "        print(\"âŒ app.py íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 9ë²ˆ ì„¹ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸš€ Streamlit ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(\"ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ë¡œ ì ‘ì†í•˜ì„¸ìš”\")\n",
    "    \n",
    "    try:\n",
    "        # Streamlit ì‹¤í–‰\n",
    "        process = subprocess.Popen([\n",
    "            'streamlit', 'run', 'app.py'\n",
    "        ])\n",
    "        \n",
    "        print(\"âœ… Streamlit ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸŒ URL: http://localhost:8501\")\n",
    "        print(\"â¹ï¸ ì¤‘ì§€í•˜ë ¤ë©´ Kernelì„ ì¬ì‹œì‘í•˜ì„¸ìš”\")\n",
    "        \n",
    "        return process\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Streamlit ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "streamlit_process = run_streamlit_app()\n",
    "\n",
    "print(\"\\nğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:\")\n",
    "print(\"âœ… ë©€í‹°ëª¨ë‹¬ RAG ê²€ìƒ‰\")\n",
    "print(\"âœ… Rerank ê¸°ë°˜ ê³ í’ˆì§ˆ ë‹µë³€\")\n",
    "print(\"âœ… ì‹¤ì‹œê°„ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤\")\n",
    "print(\"âœ… íŒŒì¼ ì—…ë¡œë“œ (PDF, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€)\")\n",
    "print(\"âœ… ì†ŒìŠ¤ ë¬¸ì„œ ì¶”ì  ë° í‘œì‹œ\")\n",
    "print(\"âœ… ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
